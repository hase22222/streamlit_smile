import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from io import  BytesIO, BufferedReader


#st.write('è‡ªåˆ†ã®é¡”ã‚’ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼')
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

face_mesh = mp_face_mesh.FaceMesh(static_image_mode = True, max_num_faces = 1, refine_landmarks = True, min_detection_confidence = 0.5)

upload_img = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ï¼", type = ['png', 'jpg'])


if upload_img is not None:
    st.image(upload_img)
    bytes_data = upload_img.getvalue()
    cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
    img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)

    results = face_mesh.process(img)
    height, width, _ = img.shape  # ç”»åƒã®å¯¸æ³•ã‚’å–å¾—
    if not results.multi_face_landmarks:
        st.write('é¡”ãŒæ¤œå‡ºã§ããªã„ã‚ˆã†ã§ã™ã€‚å†å–ã‚Šè¾¼ã¿ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚')
    else:
        for face_landmarks in results.multi_face_landmarks:
            # ç›®ã¨é¼»ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            left_eye = face_landmarks.landmark[362] # å·¦ç›®
            right_eye = face_landmarks.landmark[133] # å³ç›®
            nose_tip = face_landmarks.landmark[1] # é¼»å…ˆ

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®Yåº§æ¨™
            left_eye_y = int(left_eye.y * height)
            right_eye_y = int(right_eye.y * height)
            nose_tip_y = int(nose_tip.y * height)

        # ç›®ã¨é¼»ã®Yåº§æ¨™ãŒã»ã¼åŒã˜ã‹åˆ¤å®š
        if abs(left_eye_y - right_eye_y) <= 4.0 and abs(nose_tip_y - ((left_eye_y + right_eye_y) / 2)) >= 30:
            height, width, _ = img.shape  # ç”»åƒã®å¯¸æ³•ã‚’å–å¾—

            # åº§æ¨™ã‚’ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã«å¤‰æ›
            left_eye_cornerx  = int(results.multi_face_landmarks[0].landmark[130].x * width)     # å·¦ç›®å°»ï¼ˆxåº§æ¨™ï¼‰
            left_eye_cornery  = int(results.multi_face_landmarks[0].landmark[130].y * height)    # å·¦ç›®å°»ï¼ˆyåº§æ¨™ï¼‰
            right_eye_cornerx  = int(results.multi_face_landmarks[0].landmark[263].x * width)    # å³ç›®å°»ï¼ˆxåº§æ¨™ï¼‰
            right_eye_cornery  = int(results.multi_face_landmarks[0].landmark[263].y * height)   # å³ç›®å°»ï¼ˆyåº§æ¨™ï¼‰
            left_mouth_cornerx  = int(results.multi_face_landmarks[0].landmark[61].x * width)    # å·¦å£è§’ï¼ˆyåº§æ¨™ï¼‰
            left_mouth_cornery  = int(results.multi_face_landmarks[0].landmark[61].y * height)   # å·¦å£è§’ï¼ˆyåº§æ¨™
            right_mouth_cornerx  = int(results.multi_face_landmarks[0].landmark[291].x * width)  # å³å£è§’ï¼ˆxåº§æ¨™ï¼‰  
            right_mouth_cornery  = int(results.multi_face_landmarks[0].landmark[291].y * height) # å³å£è§’ï¼ˆyåº§æ¨™ï¼‰
            upper_ripx = int(results.multi_face_landmarks[0].landmark[13].x * width)             # ä¸Šå”‡  ï¼ˆxåº§æ¨™ï¼‰
            upper_ripy = int(results.multi_face_landmarks[0].landmark[13].y * height)            # ä¸Šå”‡  ï¼ˆyåº§æ¨™ï¼‰

            h_length = right_eye_cornerx - left_eye_cornerx    # å³ç›®å°» - å·¦ç›®å°»
            v_length1 = left_mouth_cornery - left_eye_cornery  # å·¦å£è§’ - å·¦ç›®å°»
            v_length2 = right_mouth_cornery - left_eye_cornery # å³å£è§’ - å³ç›®å°»

            #cv2.line(img, (right_eye_cornerx, right_eye_cornery), (right_eye_cornerx, right_mouth_cornery), (255, 0, 0), 2)
            #cv2.line(img, (left_eye_cornerx, left_eye_cornery), (left_eye_cornerx, left_mouth_cornery), (255, 0, 0), 2)
            #cv2.line(img, (right_eye_cornerx, right_eye_cornery), (left_eye_cornerx, left_eye_cornery), (255, 0, 0), 2)        
            #cv2.line(img, (right_eye_cornerx, right_mouth_cornery), (left_eye_cornerx, left_mouth_cornery), (255, 0, 0), 2)
            #cv2.line(img, (right_eye_cornerx, right_mouth_cornery), (upper_ripx, upper_ripy), (255, 0, 0), 2)    

        #æ¯”ç‡ã‚’è¨ˆç®—
            ratio1 = h_length / v_length1  
            ratio2 = h_length / v_length2

        # â‘ ï¼šå³å£è§’ã¨å·¦å£è§’ã®ä½ç½®ãŒã€ä¸Šå”‡ã‚ˆã‚Šä¸Šæ˜‡ã—ã¦ã„ã‚‹
            if (upper_ripy > left_mouth_cornery) & (upper_ripy > right_mouth_cornery):
              # â‘¡ï¼šã€€å·¦å³ã®ç›®å°»é–“ã®å¹…:ï¼ˆç›®å°» - å£è§’) = ç´„1.63:1ã€€ãŒé»„é‡‘æ¯”
              if (1.6 <= ratio1 <= 1.7) & (1.6 <= ratio2 <= 1.7):
                  state = 'ã“ã‚Œã¯ç´ æ™´ã‚‰ã—ã„ç¬‘é¡”ã§ã™ã­ï¼ï¼' 
              elif (1.3 <= ratio1 <=2.0) & (1.3 <= ratio2 <= 2.0):
                  state = 'è‰¯ã„ç¬‘é¡”ã§ã™ã­ï¼ã€€ã‚‚ã£ã¨ç¬‘ã£ã¦ã¿ã¾ã—ã‚‡ã†ï¼'
              else:
                  state = 'æœ¬ç‰©ã®ç¬‘é¡”ã§ã¯ãªã„ã§ã™ã­!'
            else:
                state = 'ã‚‚ã£ã¨ç¬‘ã„ã¾ã—ã‚‡ã†!'

            output_img = img.copy()
            ret, enco_img = cv2.imencode(".png", cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))

            BytesIO_img = BytesIO(enco_img.tostring())
            BufferedReader_img = BufferedReader(BytesIO_img)

            output_img2 = img.copy()
            ret2, enco_img2 = cv2.imencode(".png", cv2.cvtColor(output_img2, cv2.COLOR_BGR2RGB))

            BytesIO_img2 = BytesIO(enco_img2.tostring())
            BufferedReader_img2 = BufferedReader(BytesIO_img2)

            
            st.markdown('<style>h1{font-size: 40px; text-align: center;}</style>', unsafe_allow_html=True)
            st.markdown('<h1>ğŸ‘‡</h1>', unsafe_allow_html=True)
            st.markdown('<style>h2{font-size: 40px;}</style>', unsafe_allow_html=True)
            st.markdown('<h2>åˆ¤å®šçµæœ</h2>', unsafe_allow_html=True)
            st.markdown('<style>h3{font-size: 20px;}</style>', unsafe_allow_html=True)
            st.markdown(f'<h3>{state}</h3>', unsafe_allow_html=True)
            st.image(output_img)
        else:
           st.text("é¡”ãŒæ­£é¢ã‚’å‘ã„ã¦ã„ã¾ã›ã‚“ã€‚å†å–ã‚Šè¾¼ã¿ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")